///
/// HybridRunAnywhereSpec.hpp
/// This file was generated by nitrogen. DO NOT MODIFY THIS FILE.
/// https://github.com/mrousavy/nitro
/// Copyright Â© 2025 Marc Rousavy @ Margelo
///

#pragma once

#if __has_include(<NitroModules/HybridObject.hpp>)
#include <NitroModules/HybridObject.hpp>
#else
#error NitroModules cannot be found! Are you sure you installed NitroModules properly?
#endif



#include <NitroModules/Promise.hpp>
#include <string>
#include <optional>
#include <functional>

namespace margelo::nitro::runanywhere {

  using namespace margelo::nitro;

  /**
   * An abstract base class for `RunAnywhere`
   * Inherit this class to create instances of `HybridRunAnywhereSpec` in C++.
   * You must explicitly call `HybridObject`'s constructor yourself, because it is virtual.
   * @example
   * ```cpp
   * class HybridRunAnywhere: public HybridRunAnywhereSpec {
   * public:
   *   HybridRunAnywhere(...): HybridObject(TAG) { ... }
   *   // ...
   * };
   * ```
   */
  class HybridRunAnywhereSpec: public virtual HybridObject {
    public:
      // Constructor
      explicit HybridRunAnywhereSpec(): HybridObject(TAG) { }

      // Destructor
      ~HybridRunAnywhereSpec() override = default;

    public:
      // Properties
      

    public:
      // Methods
      virtual std::shared_ptr<Promise<bool>> createBackend(const std::string& name) = 0;
      virtual std::shared_ptr<Promise<bool>> initialize(const std::string& configJson) = 0;
      virtual std::shared_ptr<Promise<void>> destroy() = 0;
      virtual std::shared_ptr<Promise<bool>> isInitialized() = 0;
      virtual std::shared_ptr<Promise<std::string>> getBackendInfo() = 0;
      virtual std::shared_ptr<Promise<bool>> loadTextModel(const std::string& path, const std::optional<std::string>& configJson) = 0;
      virtual std::shared_ptr<Promise<bool>> isTextModelLoaded() = 0;
      virtual std::shared_ptr<Promise<bool>> unloadTextModel() = 0;
      virtual std::shared_ptr<Promise<std::string>> generateText(const std::string& prompt, const std::optional<std::string>& optionsJson) = 0;
      virtual std::shared_ptr<Promise<std::string>> generateTextStream(const std::string& prompt, const std::string& optionsJson, const std::function<void(const std::string& /* token */, bool /* isComplete */)>& callback) = 0;
      virtual std::shared_ptr<Promise<bool>> cancelGeneration() = 0;
      virtual std::shared_ptr<Promise<bool>> loadSTTModel(const std::string& path, const std::string& modelType, const std::optional<std::string>& configJson) = 0;
      virtual std::shared_ptr<Promise<bool>> isSTTModelLoaded() = 0;
      virtual std::shared_ptr<Promise<bool>> unloadSTTModel() = 0;
      virtual std::shared_ptr<Promise<std::string>> transcribe(const std::string& audioBase64, double sampleRate, const std::optional<std::string>& language) = 0;
      virtual std::shared_ptr<Promise<bool>> supportsSTTStreaming() = 0;
      virtual std::shared_ptr<Promise<bool>> loadTTSModel(const std::string& path, const std::string& modelType, const std::optional<std::string>& configJson) = 0;
      virtual std::shared_ptr<Promise<bool>> isTTSModelLoaded() = 0;
      virtual std::shared_ptr<Promise<bool>> unloadTTSModel() = 0;
      virtual std::shared_ptr<Promise<std::string>> synthesize(const std::string& text, const std::string& voiceId, double speedRate, double pitchShift) = 0;
      virtual std::shared_ptr<Promise<std::string>> getTTSVoices() = 0;
      virtual std::shared_ptr<Promise<std::string>> getLastError() = 0;
      virtual std::shared_ptr<Promise<bool>> extractArchive(const std::string& archivePath, const std::string& destPath) = 0;
      virtual std::shared_ptr<Promise<std::string>> getDeviceCapabilities() = 0;
      virtual std::shared_ptr<Promise<double>> getMemoryUsage() = 0;

    protected:
      // Hybrid Setup
      void loadHybridMethods() override;

    protected:
      // Tag for logging
      static constexpr auto TAG = "RunAnywhere";
  };

} // namespace margelo::nitro::runanywhere
