# Moltbot Configuration for Raspberry Pi with Local LLM
# Optimized for resource-constrained devices using LFM 1.2B model
#
# Copy to ~/.clawdbot/config.yaml
#
# Key optimizations:
#   1. promptMode: "local" reduces system prompt from ~30KB to ~4KB
#   2. tools.enabled: false removes ~14KB of tool schemas from prompt
#   3. Combined: reduces total prompt from ~30KB (~7800 tokens) to ~4KB (~1100 tokens)

# =============================================================================
# MODEL PROVIDERS
# =============================================================================
models:
  providers:
    runanywhere:
      baseUrl: "http://localhost:8080/v1"
      apiKey: "local"  # Must be non-empty for provider recognition
      api: openai-completions
      models:
        # LFM 1.2B - Recommended for Raspberry Pi 5
        - id: "LFM2.5-1.2B-Instruct-Q8_0"
          name: "Lobster Brain (LFM 1.2B)"
          reasoning: false
          input: ["text"]
          cost:
            input: 0
            output: 0
            cacheRead: 0
            cacheWrite: 0
          contextWindow: 16384  # CRITICAL: Must be at least 16000
          maxTokens: 4096

        # Qwen3 1.7B - Alternative with slightly better quality
        - id: "Qwen3-1.7B-Q8_0"
          name: "Qwen3 1.7B (Local)"
          reasoning: false
          input: ["text"]
          cost:
            input: 0
            output: 0
            cacheRead: 0
            cacheWrite: 0
          contextWindow: 16384
          maxTokens: 4096

# =============================================================================
# AGENT DEFAULTS
# =============================================================================
agents:
  defaults:
    # CRITICAL: Use "local" prompt mode for smaller system prompts
    # "local" mode: ~4,300 chars system prompt (vs ~10,000+ in "full" mode)
    # Note: Tool schemas are added separately - see tools section below
    promptMode: "local"
    model:
      primary: "runanywhere/LFM2.5-1.2B-Instruct-Q8_0"
      fallbacks:
        - "runanywhere/Qwen3-1.7B-Q8_0"
    compaction:
      mode: safeguard
    maxConcurrent: 4
    subagents:
      maxConcurrent: 8

# =============================================================================
# MESSAGES & COMMANDS
# =============================================================================
messages:
  ackReactionScope: group-mentions

commands:
  native: auto
  nativeSkills: auto

# =============================================================================
# GATEWAY SETTINGS
# =============================================================================
gateway:
  mode: local           # Required for gateway to start
  bind: loopback
  port: 18789
  auth:
    mode: token
    token: "REPLACE_WITH_SECURE_TOKEN"  # IMPORTANT: Change this!

# =============================================================================
# PLUGINS
# =============================================================================
plugins:
  entries:
    runanywhere:
      enabled: true
    voice-assistant:
      enabled: true
    whatsapp:
      enabled: true

# =============================================================================
# VOICE ASSISTANT CHANNEL
# =============================================================================
channels:
  voice-assistant:
    wsPort: 8082
    broadcastAllChannels: true
    accounts:
      default:
        name: "Pi Voice"
        enabled: true

# =============================================================================
# PERFORMANCE OPTIMIZATIONS
# =============================================================================
# Disable heartbeat for local LLMs (saves resources)
heartbeat:
  enabled: false

# =============================================================================
# TOOLS CONFIGURATION - CRITICAL FOR PROMPT SIZE
# =============================================================================
# WARNING: Each tool adds 500-3000 chars to the prompt via JSON schemas!
# With 18 tools enabled, this adds ~14,000+ chars (~3500+ tokens)
#
# Prompt size breakdown (observed):
#   - System prompt (local mode): ~4,300 chars (~1,100 tokens)
#   - Tool schemas (18 tools):   ~14,000 chars (~3,500 tokens)
#   - Context files:              ~3,600 chars (~900 tokens)
#   - Session history:            Variable
#   - Total with tools:          ~22,000+ chars (~5,500+ tokens)
#
# For fastest responses on Raspberry Pi, disable all tools:
tools:
  enabled: false  # Set to true to enable tools (adds ~14KB to prompt)

# If you need tools, enable only what you need:
# tools:
#   enabled: true
#   shell:
#     enabled: true   # ~1000 chars
#   fs:
#     enabled: true   # ~800 chars
#   message:
#     enabled: true   # ~3200 chars (largest tool)
#   browser:
#     enabled: false  # ~1800 chars
#   web:
#     search:
#       enabled: false
#     fetch:
#       enabled: false

# =============================================================================
# ARCHITECTURE OVERVIEW
# =============================================================================
#
# ┌─────────────────────────────────────────────────────────────┐
# │                     User Interfaces                          │
# ├────────────────┬─────────────────┬──────────────────────────┤
# │  Voice (8082)  │  WhatsApp       │  Web UI (18789)          │
# └───────┬────────┴────────┬────────┴─────────────┬────────────┘
#         │                 │                      │
#         └─────────────────┼──────────────────────┘
#                           │
#               ┌───────────▼───────────┐
#               │   Moltbot Gateway     │
#               │   (Port 18789)        │
#               │                       │
#               │  - Agent orchestration│
#               │  - Tool execution     │
#               │  - Prompt management  │
#               │  - Session handling   │
#               └───────────┬───────────┘
#                           │
#               ┌───────────▼───────────┐
#               │  RunAnywhere Server   │
#               │  (Port 8080)          │
#               │                       │
#               │  - LLM inference      │
#               │  - OpenAI-compatible  │
#               │  - llama.cpp backend  │
#               └───────────────────────┘
#
# Critical Settings for Raspberry Pi:
# - promptMode: "local" - Smaller system prompts (~4KB vs ~10KB)
# - tools.enabled: false - Removes ~14KB of tool schemas from prompt
# - contextWindow: 16384 - Moltbot minimum requirement
# - heartbeat.enabled: false - Save CPU cycles
#
# With both optimizations, a simple message uses ~1,100 tokens (vs ~7,800 with tools)
